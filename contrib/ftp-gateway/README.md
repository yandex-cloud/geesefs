# ftp-s3-gateway

__ftp-s3-gateway__ - FTP/FTPS/SFTP сервер для предоставления доступа к бакетам S3.

Реализован в формате Docker-образа, в котором запускаются стандартные FTP и SFTP
сервера vsftpd и openssh и реализация FUSE S3 файловой системы [geesefs](https://github.com/yandex-cloud/geesefs).

## Сборка образа

Склонируйте этот репозиторий и выполните команду:

```bash
docker build -t sftp-s3 .
```

## Настройки

Ключи доступа S3 и сертификаты монтируются в директорию /secrets контейнера.

### Доступ к бакету

Бакет и путь в бакете выбирается с помощью переменной окружения S3_BUCKET.

Для доступа нужно получить статический ключ и поместить его в файл secrets/credentials:

```bash
$ cat >secrets/credentials <<EOF
[default]
aws_access_key_id=KEY-ID
aws_secret_access_key=MY-SECRET-KEY
EOF
```

### Доступ SFTP (openssh)

По умолчанию включён. Выключается с помощью переменной окружения SFTP=NO.

Имя пользователя задаётся с помощью переменной окружения FTP_USER (по умолчанию "s3").
Используется авторизация по публичному ключу. Ключи нужно записать в файл
secrets/authorized_keys:

```bash
$ cat >secrets/authorized_keys <<EOF
ssh-rsa AAAAB3Nz.....BdZoeQ==
EOF
```

### Доступ FTP (vsftpd)

По умолчанию выключен. Включается с помощью переменной окружения FTP=YES.

Настраивается с помощью переменных окружения контейнера FTP_USER (по умолчанию "s3") и FTP_PASS.
Первая устанавливает имя пользователя, вторая - пароль.

### Рекомендуется: FTPS (безопасный FTP)

В обычном протоколе FTP пароли пользователей, как известно, передаются по сети в открытом виде.

Чтобы такого не было, рекомендуется включить шифрование. Для этого установите
переменную окружения FTP_SSL_ENABLE=YES (опциональное шифрование) или
FTP_SSL_ENABLE=FORCE (обязательное шифрование) и добавьте в /secrets сертификат и ключ
в файлы ftp.pem и ftp.key.

Если вы хотите включить поддержку ftps, добавьте в папку сертификат своей организации.
Если у вас нет готового сертификата, можно выписать самоподписанный:

```bash
$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout secrets/ftp.key -out secrets/ftp.pem
```

## Все настройки

### Протоколы

* FTP (YES/NO) - включить FTP
* SFTP (YES/NO) - включить SFTP
* FTP_USER - пользователь (по умолчанию "s3")
* FTP_PASS - пароль FTP. Если не указан - при запуске будет сгенерирован
  произвольный пароль, посмотреть его можно в логе контейнера

### S3

* S3_BUCKET - название бакета и путь в нём (bucket или bucket/path)
* S3_ENDPOINT - url к s3

### Пассивный режим FTP

* FTP_PASV_ENABLE (YES/NO) - по умолчанию включен
* FTP_PASV_MIN_PORT, FTP_PASV_MAX_PORT - диапазон портов для пассивного
  режима, по умолчанию 1 порт 21100 - эти порты нужно тоже пробрасывать
  из контейнера, либо запускать контейнер в режиме network=host
* FTP_PASV_ADDRESS - внешний IP-адрес сервера для пассивного режима
  (по умолчанию берётся из ip route show)
* FTP_PASV_ADDR_RESOLVE - принимать имя хоста в качестве внешнего адреса
  (по умолчанию YES)
* FTP_PASV_PROMISCUOUS - не проверять адрес клиента при пассивных подключениях
* FTP_PORT_PROMISCUOUS - не проверять порт клиента при пассивных подключениях

### FTPS

* SSL_ENABLE (YES/NO/FORCE) - по умолчанию включен
* RSA_CERT_FILE, RSA_PRIVATE_KEY_FILE - пути до сертификатов

## Запуск контейнера

Запускать можно в любом оркестраторе, главное смонтировать папку с секретами в
/secrets в контейнере, дать контейнеру права на fuse и опубликовать все нужные порты
(порт FTP, порт SSH и порты пассивного режима FTP):

```bash
docker run --cap-add SYS_ADMIN --device /dev/fuse --security-opt apparmor:unconfined \
    -it -d -e FTP=YES -e S3_BUCKET=mybucket -v /path/to/secrets:/secrets \
    -p 1021:21 -p 1022:22 -p 21100:21000 --name ftp ftp
```

## Подключение

Протестировать подключение можно с помощью утилит `sftp` и `ftp` или `lftp`.

Если вы выписали себе свой сертификат на время тестирования, не забудьте отключить его проверку в клиенте:

```bash
$ lftp
lftp :~> set ssl:verify-certificate false
lftp :~> connect 172.17.0.4
lftp 172.17.0.4:~> login billy
Password: 
lftp billy@172.17.0.4:~> ls
drwxrwx---    2 0        1000         4096 Dec 10 17:46 bucket
```

## Об асинхронности

geesefs использует кэш, в котором накапливаются данные перед отправкой в бакет, что
позволяет ускорить время загрузки. Однако, кэш не персистентный - если ваш сервер
отключится, данные пропадут и вы об этом не узнаете.

Чтобы получить гарантию на запись объекта в s3 после завершения загрузки на сервер -
клиенту необходимо явно делать fsync. В каких-то клиентах это просто включается в
настройках, например:

```
sftp -f <server_ip>
```

будет делать fsync после загрузки файла (вероятно, каждого файла) и не завершит
операцию, пока данные не доберутся до s3. Однако, такой режим замедлит скорость
загрузки.
